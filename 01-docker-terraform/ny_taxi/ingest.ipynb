{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, MetaData\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "\n",
    "# Configure logging (same as before)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define database connection details (using defaults for local testing in Jupyter)\n",
    "DB_HOST = os.environ.get(\"DB_HOST\", \"localhost\")  # Use localhost if Postgres is local\n",
    "DB_PORT = int(os.environ.get(\"DB_PORT\", 5432))\n",
    "DB_USER = os.environ.get(\"DB_USER\", \"postgres\")\n",
    "DB_PASSWORD = os.environ.get(\"DB_PASSWORD\", \"postgres\")\n",
    "DB_NAME = os.environ.get(\"DB_NAME\", \"ny_taxi\")\n",
    "\n",
    "# Define constants (same as before)\n",
    "GREEN_TAXI_TABLE_NAME = \"green_taxi_trips\"\n",
    "ZONE_LOOKUP_TABLE_NAME = \"taxi_zones\"\n",
    "GREEN_TAXI_COLUMN_MAPPINGS = {\n",
    "    \"VendorID\": \"vendor_id\",\n",
    "    \"lpep_pickup_datetime\": \"pickup_datetime\",\n",
    "    \"lpep_dropoff_datetime\": \"dropoff_datetime\",\n",
    "    \"store_and_fwd_flag\": \"store_and_fwd_flag\",\n",
    "    \"RatecodeID\": \"ratecode_id\",\n",
    "    \"PULocationID\": \"pickup_location_id\",\n",
    "    \"DOLocationID\": \"dropoff_location_id\",\n",
    "    \"passenger_count\": \"passenger_count\",\n",
    "    \"trip_distance\": \"trip_distance\",\n",
    "    \"fare_amount\": \"fare_amount\", \n",
    "    \"extra\": \"extra\",\n",
    "    \"mta_tax\": \"mta_tax\",\n",
    "    \"tip_amount\": \"tip_amount\",\n",
    "    \"tolls_amount\": \"tolls_amount\",\n",
    "    \"ehail_fee\": \"ehail_fee\",    \n",
    "    \"improvement_surcharge\": \"improvement_surcharge\",\n",
    "    \"total_amount\": \"total_amount\",\n",
    "    \"payment_type\": \"payment_type\",\n",
    "    \"trip_type\":\"trip_type\",\n",
    "    \"congestion_surcharge\": \"congestion_surcharge\",\n",
    "}\n",
    "\n",
    "ZONE_LOOKUP_COLUMN_MAPPINGS = {\n",
    "    \"LocationID\": \"location_id\",\n",
    "    \"Borough\": \"borough\",\n",
    "    \"Zone\": \"zone\",\n",
    "    \"service_zone\": \"service_zone\",\n",
    "}\n",
    "CHUNK_SIZE = 100000\n",
    "GREEN_TAXI_URL = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\"\n",
    "ZONE_LOOKUP_URL = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "\n",
    "def download_data(url):\n",
    "    \"\"\"Downloads data from the given URL and returns it as BytesIO object.\"\"\"\n",
    "    logging.info(f\"Downloading data from {url}...\")\n",
    "    try:\n",
    "        response = urlretrieve(url)\n",
    "        with open(response[0], 'rb') as f:\n",
    "            data = BytesIO(f.read())\n",
    "        logging.info(f\"Download complete.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_database_engine():\n",
    "    \"\"\"Creates a SQLAlchemy engine.\"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "        engine.connect()  # Test the connection immediately\n",
    "        logging.info(\"Database connection successful.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating database engine: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_tables(engine):\n",
    "    \"\"\"Creates the database tables.\"\"\"\n",
    "    metadata_obj = MetaData()\n",
    "    Base = declarative_base(metadata=metadata_obj)\n",
    "\n",
    "    class GreenTaxiTrip(Base):\n",
    "        __tablename__ = GREEN_TAXI_TABLE_NAME\n",
    "        trip_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "        # ... (other columns same as before)\n",
    "    class ZoneLookup(Base): #... (same as before)\n",
    "\n",
    "    try:\n",
    "        Base.metadata.create_all(engine)\n",
    "        logging.info(\"Tables created successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating tables: {e}\")\n",
    "\n",
    "def ingest_data(engine, data, table_name, column_mappings, table_class):\n",
    "    \"\"\"Ingests data from a BytesIO object into the database.\"\"\"\n",
    "    logging.info(f\"Ingesting data into {table_name}...\")\n",
    "    try:\n",
    "        df_chunks = pd.read_csv(data, chunksize=CHUNK_SIZE, dtype='str', compression='gzip' if table_name == GREEN_TAXI_TABLE_NAME else None)\n",
    "        for i, chunk in enumerate(df_chunks):\n",
    "            logging.info(f\"Processing chunk {i+1}...\")\n",
    "            chunk = chunk.rename(columns=column_mappings)\n",
    "            for col, dtype in table_class.__table__.columns.items():\n",
    "                if col in chunk.columns:\n",
    "                    if dtype.type.__class__.__name__ == 'DateTime':\n",
    "                        chunk[col] = pd.to_datetime(chunk[col], errors='coerce')\n",
    "                    elif dtype.type.__class__.__name__ in ('Integer', 'Float'):\n",
    "                        chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n",
    "            chunk.to_sql(name=table_name, con=engine, if_exists='append', index=False)\n",
    "            logging.info(f\"Chunk {i+1} ingested.\")\n",
    "        logging.info(f\"Data ingestion into {table_name} complete.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error ingesting data: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    try:\n",
    "        engine = create_database_engine()\n",
    "        if engine is None:\n",
    "            raise Exception(\"Engine not created\")\n",
    "        create_tables(engine)\n",
    "\n",
    "        green_taxi_data = download_data(GREEN_TAXI_URL)\n",
    "        if green_taxi_data is None:\n",
    "            raise Exception(\"Green Taxi data not downloaded\")\n",
    "        ingest_data(engine, green_taxi_data, GREEN_TAXI_TABLE_NAME, GREEN_TAXI_COLUMN_MAPPINGS, GreenTaxiTrip)\n",
    "\n",
    "        zone_lookup_data = download_data(ZONE_LOOKUP_URL)\n",
    "        if zone_lookup_data is None:\n",
    "            raise Exception(\"Zone Lookup data not downloaded\")\n",
    "        ingest_data(engine, zone_lookup_data, ZONE_LOOKUP_TABLE_NAME, ZONE_LOOKUP_COLUMN_MAPPINGS, ZoneLookup)\n",
    "\n",
    "        logging.info(\"All operations completed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"A critical error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
